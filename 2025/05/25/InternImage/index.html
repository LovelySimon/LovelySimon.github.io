<!DOCTYPE HTML>
<html>
<head>
  <meta charset="utf-8">
  <meta http-equiv="pragma" content="no-cache">
  <meta http-equiv="cache-control" content="no-cache">
  <meta http-equiv="expires" content="0">
  
  <title>InternImage:Exploring Large-Scale Vision Foundation Models with Deformable Convolutions | 哥们废了</title>
  <meta name="author" content="Simon An">
  
  <meta name="description" content="记录在NJUST学习和生活历程">
  
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  <meta property="og:title" content="InternImage:Exploring Large-Scale Vision Foundation Models with Deformable Convolutions"/>
  <meta property="og:site_name" content="哥们废了"/>

  
    <meta property="og:image" content=""/>
  

  
  
  
  <link rel="stylesheet" href="/css/bootstrap.min.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/css/font-awesome.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/css/style.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/css/responsive.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/css/highlight.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/css/google-fonts.css" media="screen" type="text/css">
  <!--[if lt IE 9]><script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->

  <script src="/js/jquery-2.0.3.min.js"></script>

  <!-- analytics -->
  
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
  ga('create', 'UA-70812759-1', 'auto');
  ga('send', 'pageview');
</script>



<meta name="generator" content="Hexo 7.3.0"></head>

 <body>  
  <nav id="main-nav" class="navbar navbar-inverse navbar-fixed-top" role="navigation">
    <div class="container">
      <button type="button" class="navbar-header navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
		<span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
	  <a class="navbar-brand" href="/">哥们废了</a>
      <div class="collapse navbar-collapse nav-menu">
		<ul class="nav navbar-nav">
		  
		  <li>
			<a href="/archives" title="All the articles.">
			  <i class=""></i>Archives
			</a>
		  </li>
		  
		  <li>
			<a href="/categories" title="All the categories.">
			  <i class=""></i>Categories
			</a>
		  </li>
		  
		  <li>
			<a href="/tags" title="All the tags.">
			  <i class=""></i>Tags
			</a>
		  </li>
		  
		  <li>
			<a href="/about" title="About me.">
			  <i class=""></i>About
			</a>
		  </li>
		  
		</ul>
      </div>
    </div> <!-- container -->
</nav>
<div class="clearfix"></div>

  <div class="container">
  	<div class="content">
    	 


	
		<div class="page-header">
			<h1> InternImage:Exploring Large-Scale Vision Foundation Models with Deformable Convolutions</h1>
		</div>
	



<div class="row post">
	<!-- cols -->
	
	<div id="top_meta"></div>
	<div class="col-md-9">
	

	<!-- content -->
	<div class="mypage">		
	  		

	  <h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p>​	Compared to the great progress of large-scale vision transformers (ViTs) in recent years, large-scale models based on convolutional neural networks (CNNs) are still in an early state. This work presents a new large-scale CNN-based foundation model, termed InternImage, which can obtain the gain from increasing parameters and training data like ViTs. Different from the recent CNNs that focus on large dense kernels, InternImage takes deformable convolution as the core operator, so that our model not only has the large effective receptive field required for downstream tasks such as detection and segmentation, but also has the adaptive spatial aggregation conditioned by input and task information. As a result, the proposed InternImage reduces the strict inductive bias of traditional CNNs and makes it possible to learn stronger and more robust patterns with large-scale parameters from massive data like ViTs. The effectiveness of our model is proven on challenging benchmarks including ImageNet, COCO, and ADE20K. It is worth mentioning that InternImage-H achieved a new record 65.4 mAP on COCO test-dev and 62.9 mIoU on ADE20K, outperforming current leading CNNs and ViTs.</p>
<p>作者认为，现如今CNN网络与主流的Vit框架的差距主要在于两个方面：</p>
<ol>
<li>多头自注意力机制具有长程依赖性和自适应空间聚集性，vit会比cnn在大量数据上学习到更加强大且鲁棒性高的数据表示。</li>
<li>从架构角度来说，Vit含有许多CNN不具备的高级组件，如LayerNormalization，FFN ，GELU等。</li>
</ol>
<h2 id="Method"><a href="#Method" class="headerlink" title="Method"></a>Method</h2><p>为了设计一个大规模的CNN网络模型，作者使用一个灵活的卷积变体，命名为DCNv2，并且为其进行了调整以更好适应大规模模型。接着，作者将基本模块与在现如今架构中先进的模块设计结合，最后作者探索了基于DCN的块的堆叠和缩放原理，以构建能够从海量数据中学习强表示的大规模卷积模型。</p>
<h3 id="Deformable-Convolution-v3"><a href="#Deformable-Convolution-v3" class="headerlink" title="Deformable Convolution v3"></a>Deformable Convolution v3</h3><p>之前的工作[ 21、22、50]已经广泛讨论了CNNs和ViTs的区别。在确定Intern Image的核心算子之前，作者首先总结了正则卷积和MHSA的主要区别。</p>
<ol>
<li>长程依赖：尽管人们早已认识到具有较大有效感受野(长程依赖)的模型通常在下游视觉任务上表现更好，但是33的规则卷积核的实际感受野较小，即使是非常深的模型基于CNN的模型也无法获得vit的长程依赖，这限制了他的性能。</li>
<li>自适应空间聚集：自适应空间聚合是指模型在处理视觉信息时，能够根据输入数据的特征和任务需求，动态调整对不同空间位置信息的聚合方式，而非采用固定的规则。常规卷积是一种具有静态权重和强归纳偏置的算子，例如二维局部性、邻域结构、平移不变性等。这高度归纳的特性使得常规卷积组成的模型可能比vit收敛的更快，所需要的训练数据更少，但也限制了卷积神经网络从大规模数据中学习到更加通用，具有鲁棒性的能力。</li>
</ol>
<p>弥合卷积和MHSA之间鸿沟的一个简单方法是在正则卷积中引入长程依赖和自适应空间聚合。</p>
<p>可变形卷积 v2（DCNv2）正是这样一种改进的卷积算子，它通过灵活调整采样位置和权重，成为连接卷积与 MHSA 的关键一步。</p>
<p><img src="https://simonpic-1330571413.cos.ap-nanjing.myqcloud.com/picblog/image-20250523143139013.png" alt="image-20250523143139013"></p>
<p><img src="https://simonpic-1330571413.cos.ap-nanjing.myqcloud.com/picblog/image-20250523143159510.png" alt="image-20250523143159510"></p>
<ul>
<li><p><strong>输入特征图</strong>：x 是维度为 (\mathbb{R}^{C \times H \times W}) 的特征图，其中 C 为通道数，(H \times W) 为空间尺寸。</p>
</li>
<li><p><strong>当前像素位置</strong>：(p_0 &#x3D; (i, j)) 表示输出特征图中当前像素的坐标（如二维图像中的行和列）。</p>
</li>
<li><p>采样位置计算：(p_0 + p_k + Delta p_k)</p>
<p>表示输入特征图中实际采样点的坐标，其中：</p>
<ul>
<li>pk是预定义的固定网格偏移（如 3×3 卷积的 9 个基础位置，如 (p_1 &#x3D; (-1, -1)) 对应左上角）；</li>
<li>是可学习的动态偏移量（如通过训练得到的额外偏移，允许采样点 “变形”）。</li>
</ul>
</li>
</ul>
<p>在传统应用中，DCNv2 通常作为常规卷积的 “插件” 使用，依赖预训练权重（如 ImageNet 预训练的 ResNet 权重）进行微调：</p>
<ol>
<li><strong>参数与内存复杂度高</strong>：原始 DCNv2 中每个卷积神经元（如 3×3 卷积的 9 个采样点）拥有独立的投影权重 (w_k \in \mathbb{R}^{C \times C})，参数总量与采样点数量呈线性关系（如 C&#x3D;256 时，9 个采样点的权重参数达 (9 \times 256 \times 256 &#x3D; 589,824)），在大规模模型中（如 10 亿参数）会导致内存爆炸。</li>
<li><strong>训练策略依赖预训练</strong>：常规 DCNv2 通过加载预训练权重初始化，再微调优化，这种方式适用于中小规模模型，但大规模基础模型（如需要从 4 亿图像中从头训练）难以依赖预训练，需独立学习参数。</li>
<li><strong>稳定性问题</strong>：原始 DCNv2 中调制标量 (m_k) 使用 Sigmoid 归一化，其和不固定（范围 0 到 K），在大规模数据训练时易导致梯度不稳定，尤其当模型深度和宽度增加时，优化难度显著上升。</li>
</ol>
<p>作者对DCNv2进行改进以使其适用于大规模训练，主要优化如下：</p>
<p>Sharing weights among convolutional neurons.将wk分解为深度-wise部分和点-wise部分，其中深度部分由mk替代，点部分由所有采样点共享一组投影权重w</p>
<p><img src="https://simonpic-1330571413.cos.ap-nanjing.myqcloud.com/picblog/image-20250523144849748.png" alt="image-20250523144849748"></p>
<p>Introducing multi-group mechanism.作者受到多头注意力机制的启发，将空间聚合过程拆分为G个组，每个组具有单独的采样偏移量∆pgk和调制尺度mgk，因此单个卷积层上的不同组可以具有不同的空间聚合模式，从而为下游任务提供更强的特征。得到DCN v3</p>
<p>v3的三个优点：</p>
<ol>
<li>弥补了卷积网络对长程依赖和适应性空间聚集的不足</li>
<li>与多头自注意力相比更加节省内存和训练时间</li>
<li>该算子基于稀疏采样，比之前的方法如MHSA和重新参数化大核等具有更高的计算和内存效率。</li>
</ol>
<h3 id="InternImage-Model"><a href="#InternImage-Model" class="headerlink" title="InternImage Model"></a>InternImage Model</h3><p>基础模块搭建：与传统的CNN网络不同，internimage的模块设计更加接近于Vit模型，装配了更加先进的组件，包括LN，FFN前馈网络，GELU等</p>
<p>采样偏置和调制尺度通过可分离卷积输入特征x来决定</p>
<p><img src="https://simonpic-1330571413.cos.ap-nanjing.myqcloud.com/picblog/image-20250523230117215.png" alt="image-20250523230117215"></p>
<p>Stem &amp; downsampling layers：为了获得层次化的特征图，使用卷积主干和下采样层将特征图调整到不同的尺度。stem层将输入分辨率缩小四倍，stem设计如下：<img src="https://simonpic-1330571413.cos.ap-nanjing.myqcloud.com/picblog/image-20250523232840170.png" alt="image-20250523232840170"></p>
<p>下采样模块设计：<img src="https://simonpic-1330571413.cos.ap-nanjing.myqcloud.com/picblog/image-20250523232946614.png" alt="image-20250523232946614"></p>
<p>堆叠方式：采用四阶段堆叠，堆叠规则可概括为以下四点：</p>
<ol>
<li>通道数堆叠规则：第i阶段的通道数(C_i)由第 1 阶段通道数(C_1)决定，遵循指数递增，通过指数级通道数增长，匹配视觉任务中特征图分辨率递减的需求<ul>
<li>stage1：C1	</li>
<li>stage2：2*C1</li>
<li>stage3：4*C1</li>
<li>stage4：8*C1</li>
</ul>
</li>
<li>分组数与通道数关联：</li>
</ol>
<p><img src="https://simonpic-1330571413.cos.ap-nanjing.myqcloud.com/picblog/image-20250525155452892.png" alt="image-20250525155452892"></p>
<ol start="3">
<li>模块数遵循AABA分布：</li>
</ol>
<p><img src="https://simonpic-1330571413.cos.ap-nanjing.myqcloud.com/picblog/image-20250525155538292.png" alt="image-20250525155538292"></p>
<ol start="4">
<li>超参数降维</li>
</ol>
<p><img src="https://simonpic-1330571413.cos.ap-nanjing.myqcloud.com/picblog/image-20250525155620131.png" alt="image-20250525155620131"></p>
	  
	</div>

	<div>
  	<center>
	<div class="pagination">

    
    
    <a href="/2025/05/28/pfnet/" type="button" class="btn btn-default"><i
                class="fa fa-arrow-circle-o-left"></i> 上一页</a>
    

    <a href="/" type="button" class="btn btn-default"><i class="fa fa-home"></i>Home</a>
    
    <a href="/2025/05/22/MoCo/" type="button" class="btn btn-default ">下一页<i
                class="fa fa-arrow-circle-o-right"></i></a>
    

    
</div>

    </center>
	</div>
	
	<!-- comment -->
	
<section id="comment">
    <h2 class="title">留言</h2>

    
</section>


	</div> <!-- col-md-9/col-md-12 -->
		
	
	<div id="side_meta">
		<div class="col-md-3" id="post_meta"> 

	<!-- date -->
	
	<div class="meta-widget">
	<i class="fa fa-clock-o"></i>
	2025-05-25 
	</div>
	

	<!-- categories -->
    

	<!-- tags -->
	
	<div class="meta-widget">
	<a data-toggle="collapse" data-target="#tags"><i class="fa fa-tags"></i></a>		  
    <ul id="tags" class="tag_box list-unstyled collapse in">	  
	    
  <li><a href="/tags/ML/">ML<span>3</span></a></li>
    </ul>
	</div>
		

	<!-- toc -->
	<div class="meta-widget">
	
	</div>
	
    <hr>
	
</div><!-- col-md-3 -->

	</div>
		

</div><!-- row -->



	</div>
  </div>
  <div class="container-narrow">
  <footer> <p>
  &copy; 2025 Simon An
  
      with help from <a href="http://hexo.io/" target="_blank">Hexo</a>,<a target="_blank" rel="noopener" href="http://github.com/wzpan/hexo-theme-freemind/">Freemind</a>,<a href="http://getbootstrap.com/" target="_blank">Twitter Bootstrap</a> and <a href="http://getbootstrap.com/" target="_blank">BOOTSTRA.386</a>. 
     <br> Theme by <a target="_blank" rel="noopener" href="http://github.com/wzpan/hexo-theme-freemind/">Freemind.386</a>.    
</p>
 </footer>
</div> <!-- container-narrow -->
  


  
<a id="gotop" href="#">   
  <span>⬆︎TOP</span>
</a>

<script src="/js/jquery.imagesloaded.min.js"></script>
<script src="/js/gallery.js"></script>
<script src="/js/bootstrap.min.js"></script>
<script src="/js/main.js"></script>
<script src="/js/search.js"></script> 




   <script type="text/javascript">      
     var search_path = "search.xml";
	 if (search_path.length == 0) {
	 	search_path = "search.xml";
	 }
	 var path = "/" + search_path;
     searchFunc(path, 'local-search-input', 'local-search-result');
   </script>

</body>
   </html>
